{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created by Pooja Subramaniam and Marc Aurel Vischer on Tue, May 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperature is given as a tuple of daily high and low value, both in degrees Celsius as ints.\n",
    "\n",
    "Precipitation is given as \"probability\" as float.\n",
    "\n",
    "Wind is given as a tuple of strength in Bft (int) and direction (e.g. \"NE\" if wind _comes from_ north east)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib3\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Daily = pd.DataFrame({'date_of_acquisition':[], 'website':[], 'city':[], 'date_of_prediction':[], \n",
    "#                      'temp_low':[], 'temp_high':[], 'wind_speed':[], 'wind_direction':[],'precipitation':[]})\n",
    "#Daily_periods = pd.DataFrame({'day_of_acquisition':[],'website':[], 'city':[],\n",
    "#                              'date_of_prediction':[],'time_for_which_weather_is_predicted':[],'temp_low':[], 'temp_high':[],\n",
    "#                    'wind_speed':[], 'wind_direction':[],'precipitation':[]})\n",
    "\n",
    "Daily_dict = {}\n",
    "Daily_periods = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#These are the urls referring directly to high, low temperature\n",
    "hi_lo_url = \"https://wetter.bild.de/web2014/ifr-wetter-deutschland.asp\"\n",
    "prec_url = \"https://wetter.bild.de/web2014/ifr-niederschlag-deutschland.asp\"\n",
    "wind_url = \"https://wetter.bild.de/web2014/ifr-windstaerken-deutschland.asp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pooja\\AppData\\Local\\conda\\conda\\envs\\webscrapping\\lib\\site-packages\\urllib3\\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\Pooja\\AppData\\Local\\conda\\conda\\envs\\webscrapping\\lib\\site-packages\\urllib3\\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "C:\\Users\\Pooja\\AppData\\Local\\conda\\conda\\envs\\webscrapping\\lib\\site-packages\\urllib3\\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    }
   ],
   "source": [
    "#load and parse page\n",
    "http = urllib3.PoolManager()\n",
    "hi_lo_bs = BeautifulSoup(http.request('GET', hi_lo_url).data, \"html.parser\")\n",
    "prec_bs = BeautifulSoup(http.request('GET',prec_url).data, \"html.parser\")\n",
    "wind_bs = BeautifulSoup(http.request('GET',wind_url).data, \"html.parser\")\n",
    "#print(hi_lo.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TEMPERATURE HIGH/LOW, bild has today + 5 days forecast for that\n",
    "#iterate over days, extract day layer for each\n",
    "temp_dicts = []\n",
    "for day in range(6):\n",
    "    # extract current day layer\n",
    "    day_layer = hi_lo_bs.find_all('div', id=\"wk_layer_wr{}\".format(day))\n",
    "    #print(day_layer[0]['id'])\n",
    "    if len(day_layer)!=1:\n",
    "        raise Exception(\"Found more than one layer for single day.\")\n",
    "        \n",
    "    # extract all the cities from that layer\n",
    "    day_cities = day_layer[0].find_all('div', class_=\"wk_map_text\")\n",
    "    day_dict = {}\n",
    "    for city in day_cities:\n",
    "        hi_lo_str = city.nobr.nextSibling.nextSibling\n",
    "        high = int(hi_lo_str.split('|')[0].split('°')[0])\n",
    "        low = int(hi_lo_str.split('|')[1].split('°')[0])\n",
    "        day_dict[city.nobr.string] = (high, low)\n",
    "    temp_dicts.append(day_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PRECIPITATION,  bild has only today + 2 days forecast for that\n",
    "#iterate over days, extract day layer for each\n",
    "prec_dicts = []\n",
    "for day in range(1,4): #layer 0 corresponds to next 6 hrs, layer 1 to entire current day\n",
    "    # extract current day layer\n",
    "    day_layer = prec_bs.find_all('div', id=\"wk_layer_wr{}\".format(day))\n",
    "    #print(day_layer[0]['id'])\n",
    "    if len(day_layer)!=1:\n",
    "        raise Exception(\"Found more than one layer for single day.\")\n",
    "        \n",
    "    # extract all the cities from that layer\n",
    "    day_cities = day_layer[0].find_all('div', class_=\"wk_map_text\")\n",
    "    day_dict = {}\n",
    "    for city in day_cities:\n",
    "        prec_str = city.nobr.nextSibling.nextSibling\n",
    "        prec_value = int(prec_str.split()[0])/100\n",
    "        day_dict[city.nobr.string] = prec_value\n",
    "    prec_dicts.append(day_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#WIND,  bild again has today + 5 days forecast\n",
    "WIND_GER_ENG = {\"w\":\"W\", \"nw\":\"NW\", \"n\":\"N\", \"no\":\"NE\", \"o\":\"E\", \"so\":\"SE\", \"s\":\"S\", \"sw\":\"SW\"}\n",
    "#iterate over days, extract day layer for each\n",
    "wind_dicts = []\n",
    "for day in range(6):\n",
    "    # extract current day layer\n",
    "    day_layer = wind_bs.find_all('div', id=\"wk_layer_wr{}\".format(day))\n",
    "    #print(day_layer[0]['id'])\n",
    "    if len(day_layer)!=1:\n",
    "        raise Exception(\"Found more than one layer for single day.\")\n",
    "        \n",
    "    # extract all the cities from that layer\n",
    "    day_cities = day_layer[0].find_all('div', class_=\"wk_map_text\")\n",
    "    day_dict = {}\n",
    "    for city in day_cities:\n",
    "        wind_str = city.nobr.nextSibling.nextSibling\n",
    "        wind_strength = int(wind_str.split()[0])\n",
    "        wind_symbol_url = city.parent.img['src']\n",
    "        wind_direction_raw = wind_symbol_url.split('.')[0].split('/')[-1]\n",
    "        wind_direction = WIND_GER_ENG[wind_direction_raw]\n",
    "        day_dict[city.nobr.string] = (wind_strength,wind_direction)\n",
    "    wind_dicts.append(day_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "Date_of_acquisition = datetime.datetime.now()\n",
    "Website = ['Bild.de']\n",
    "City = ['Berlin','Frankfurt','Hamburg','Köln','München']\n",
    "Times_of_day = ['2AM','8AM','2PM','8PM']\n",
    "Daily_dict = {'Date_of_acquisition':[],'Website':[],'City':[],\n",
    "              'Date_of_prediction':[],'high_temp':[],'low_temp':[],'wind_speed':[],'wind_direction':[], 'precipitation':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,city in enumerate(City):\n",
    "    for days in range(6):\n",
    "        \n",
    "        Daily_dict['Date_of_acquisition'].append(datetime.datetime.now().isoformat())\n",
    "        Daily_dict['Website'].append(Website)\n",
    "        Daily_dict['City'].append(city)\n",
    "        Daily_dict['Date_of_prediction'].append(Date_of_acquisition+datetime.timedelta(days))\n",
    "        Daily_dict['high_temp'].append(temp_dicts[days][city][0])\n",
    "        Daily_dict['low_temp'].append(temp_dicts[days][city][1])\n",
    "        Daily_dict['wind_speed'].append(wind_dicts[days][city][0])\n",
    "        Daily_dict['wind_direction'].append(wind_dicts[days][city][1])\n",
    "\n",
    "        if days<2:\n",
    "            Daily_dict['precipitation'].append(prec_dicts[days+1][city]*100)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Daily = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in Daily_dict.items() ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import tempfile\n",
    "filename = pathlib.Path(str(datetime.datetime.now().date()))\n",
    "pd.DataFrame.to_csv(Daily, path_or_buf = tempfile.gettempdir() / filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:webscrapping]",
   "language": "python",
   "name": "conda-env-webscrapping-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
